{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import zipfile\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n",
      "Current : 0\n",
      "Count : 1\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print('device :', device)\n",
    "print('Current :', torch.cuda.current_device())\n",
    "print('Count :', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>등록번호</th>\n",
       "      <th>생년월일</th>\n",
       "      <th>성별</th>\n",
       "      <th>진료의</th>\n",
       "      <th>검사 시 나이</th>\n",
       "      <th>신장</th>\n",
       "      <th>체중</th>\n",
       "      <th>BMI</th>\n",
       "      <th>처방일자</th>\n",
       "      <th>시행일자</th>\n",
       "      <th>BA 1</th>\n",
       "      <th>BA 2</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>No</th>\n",
       "      <th>boneage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1698</td>\n",
       "      <td>8255049</td>\n",
       "      <td>2007-08-03</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>9.969863</td>\n",
       "      <td>129.5</td>\n",
       "      <td>26.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>9.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1897</td>\n",
       "      <td>8537405</td>\n",
       "      <td>2008-08-22</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>9.989041</td>\n",
       "      <td>132.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>10.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>10.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422</td>\n",
       "      <td>7942635</td>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10.008219</td>\n",
       "      <td>136.4</td>\n",
       "      <td>33.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>11.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1475</td>\n",
       "      <td>7995857</td>\n",
       "      <td>2005-02-09</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10.049315</td>\n",
       "      <td>133.5</td>\n",
       "      <td>31.2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>10.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1888</td>\n",
       "      <td>8520261</td>\n",
       "      <td>2008-09-11</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10.060274</td>\n",
       "      <td>130.6</td>\n",
       "      <td>23.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.jpg</td>\n",
       "      <td>9.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group     등록번호        생년월일 성별 진료의    검사 시 나이     신장    체중   BMI  \\\n",
       "0   1698  8255049  2007-08-03  F   1   9.969863  129.5  26.9  16.1   \n",
       "1   1897  8537405  2008-08-22  F   1   9.989041  132.0  31.0  17.8   \n",
       "2   1422  7942635  2005-01-19  F   1  10.008219  136.4  33.2  17.9   \n",
       "3   1475  7995857  2005-02-09  F   1  10.049315  133.5  31.2  17.6   \n",
       "4   1888  8520261  2008-09-11  F   1  10.060274  130.6  23.7  13.9   \n",
       "\n",
       "         처방일자        시행일자   BA 1   BA 2 Unnamed: 14     No  boneage  \n",
       "0  2017-01-09  2017-07-20   9.75   9.75         NaN  1.jpg    9.750  \n",
       "1  2018-02-28  2018-08-16  10.50  11.00         NaN  2.jpg   10.750  \n",
       "2  2015-01-20  2015-01-20  11.00  11.25         NaN  3.jpg   11.125  \n",
       "3  2015-02-25  2015-02-25  10.00  10.25         NaN  4.jpg   10.125  \n",
       "4  2018-10-01  2018-10-01  10.00   9.75         NaN  5.jpg    9.875  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('골밀도 데이터/total_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_img(r1,r2,r3,r4):\n",
    "    tmp_binary_img = []\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) #CLAHE 생성\n",
    "    for img in [r1,r2,r3,r4]:\n",
    "        if img is not None:\n",
    "            # resized_img = cv2.resize(img,(1000,400)) # (400, 500)\n",
    "            blured_img = cv2.GaussianBlur(img,(5,5),0)            \n",
    "            clahed_img = clahe.apply(blured_img)          #CLAHE 적용\n",
    "            # _,binary_img = cv2.threshold(clahed_img,clahed_img.mean()*1.25,255,cv2.THRESH_BINARY)\n",
    "            \n",
    "            target_length = 500\n",
    "            (original_height, original_width) = clahed_img.shape\n",
    "            # 가로세로 비율을 유지하면서 긴 부분을 target_length로 조정합니다.\n",
    "            if original_width > original_height:\n",
    "                # 가로가 길 경우\n",
    "                new_width = target_length\n",
    "                new_height = int((new_width / original_width) * original_height)\n",
    "            else:\n",
    "                # 세로가 길 경우\n",
    "                new_height = target_length\n",
    "                new_width = int((new_height / original_height) * original_width)\n",
    "\n",
    "            # 이미지 크기 조정\n",
    "            resized_image = cv2.resize(clahed_img, (new_width, new_height))\n",
    "            \n",
    "            # 최종 이미지 크기\n",
    "            target_size = 600\n",
    "            old_size = resized_image.shape\n",
    "\n",
    "            # 새로운 이미지 생성 (검은색 배경)\n",
    "            new_image = np.zeros((target_size, target_size), dtype=np.uint8)\n",
    "\n",
    "            # 이미지 중앙에 배치하기 위한 좌표 계산\n",
    "            start_x = (target_size - old_size[1]) // 2\n",
    "            start_y = (target_size - old_size[0]) // 2\n",
    "\n",
    "            # 원본 이미지를 중앙에 배치\n",
    "            new_image[start_y:start_y+old_size[0], start_x:start_x+old_size[1]] = resized_image\n",
    "            \n",
    "            tmp_binary_img.append(new_image)\n",
    "                \n",
    "    return np.array(tmp_binary_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, roi_1, roi_2, roi_3, roi_4):\n",
    "    \n",
    "    cropped_roi_1_img = img[roi_1[0][1]:roi_1[1][1],roi_1[0][0]:roi_1[1][0]]\n",
    "    cropped_roi_2_img = img[roi_2[0][1]:roi_2[1][1],roi_2[0][0]:roi_2[1][0]]\n",
    "    cropped_roi_3_img = img[roi_3[0][1]:roi_3[1][1],roi_3[0][0]:roi_3[1][0]]\n",
    "    cropped_roi_4_img = img[roi_4[0][1]:roi_4[1][1],roi_4[0][0]:roi_4[1][0]]\n",
    "\n",
    "    optimzed_imgs = optimize_img(cropped_roi_1_img, cropped_roi_2_img, cropped_roi_3_img, cropped_roi_4_img)\n",
    "    return optimzed_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation - rotation + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = [], []\n",
    "X_aug_rot, y_aug_rot = [], []\n",
    "X_aug_noise, y_aug_noise = [], []\n",
    "# X_aug_resort, y_aug_resort = [], []\n",
    "\n",
    "for k in range(len(data)):\n",
    "    if k == 354 or k == 355 or k == 916:\n",
    "        continue\n",
    "    img0 = cv2.imread('골밀도 데이터/rotate_image/' + data.No[k], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 이미지 thresholding\n",
    "    r_img = np.copy(img0)\n",
    "    height, width = img0.shape\n",
    "    img = img0[0:(int)(height*0.9),0:(int)(width*0.95)]\n",
    "    ret, img = cv2.threshold(img, img0.mean(), 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 이미지 contouring\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_cnt = max(contours, key = cv2.contourArea)\n",
    "    mask = np.zeros(img.shape, dtype= np.uint8)\n",
    "    cv2.drawContours(mask, [max_cnt], -1, (255, 255, 255), -1)\n",
    "\n",
    "    # 볼록한 점 구하기\n",
    "    hull = cv2.convexHull(max_cnt, returnPoints= False)\n",
    "    hull1 = cv2.convexHull(max_cnt)\n",
    "\n",
    "    # 오목한 지점 구하기\n",
    "    defects = cv2.convexityDefects(max_cnt, hull) # 인덱스로 반환\n",
    "\n",
    "    # 거리를 저장할 수 있는 공간 생성\n",
    "    di = []\n",
    "\n",
    "    for index in range(defects.shape[0]):\n",
    "        # 시작점, 끝점, far 점, 거리 할당\n",
    "        sp, ep, fp, distance = defects[index, 0]\n",
    "        \n",
    "        # 거리 저장\n",
    "        di.append(distance)\n",
    "\n",
    "    far_xrange = []\n",
    "    far_yrange = []\n",
    "    start_xrange = []\n",
    "    start_yrange = []\n",
    "\n",
    "    # 가장 오목하게 들어가 있는 부분을 찾기 위해 sorting(내림차순)\n",
    "    di = np.array(di)\n",
    "    s_di = np.sort(di)[::-1]\n",
    "\n",
    "    # 내림차순된 거리들을 6개만 뽑아내기 위해 slice\n",
    "    for i in list(s_di[:6]):\n",
    "        index = np.where(di == i)[0][0]\n",
    "        \n",
    "        sp, ep, fp, _ = defects[index, 0]\n",
    "        \n",
    "        far_xrange.append(max_cnt[fp][0][0])\n",
    "        far_yrange.append(max_cnt[fp][0][1])\n",
    "        \n",
    "        start_xrange.append(max_cnt[sp][0][0])\n",
    "        start_yrange.append(max_cnt[sp][0][1])\n",
    "        \n",
    "\n",
    "    #손목뼈 ROI\n",
    "    carpus_sp = ((int)(min(far_xrange[4:6])*0.90),(int)(max(far_yrange[4:6])*0.90))\n",
    "    carpus_ep = (int(max(far_xrange[4:6])*1.05),(int)(max(far_yrange[4:6])*1.15))\n",
    "\n",
    "    #손목뼈 위쪽에 있는 관절 4개를 추출\n",
    "    four_sp = ((int)(min(far_xrange[0:4])*0.70),int(min(far_yrange[0:4])*0.95))\n",
    "    four_ep = (int(max(far_xrange[0:4])*1.05),(int)(max(far_yrange[0:4])*1.05))\n",
    "\n",
    "    #중지 ROI 추출\n",
    "    #중지 끝 좌표 구하기\n",
    "    for y,x_r in enumerate(mask) :\n",
    "        if 255 in x_r:\n",
    "            #y에 따른 x rows 중 255인 x값 추출\n",
    "            x_255_indexs = np.where(x_r == 255)[0]\n",
    "\n",
    "            #255인 x값들 중 median 추출\n",
    "            x_255_mid_index = x_255_indexs[(int)(len(x_255_indexs)/2)]\n",
    "            first_255_x_point = x_255_mid_index\n",
    "\n",
    "            first_255_y_point = y\n",
    "            break\n",
    "        \n",
    "    ## 중지 끝 좌표에서 처음 오목한 곳의 x 좌표를 뺀 간격만큼\n",
    "    sub = min(abs(first_255_x_point - far_xrange[0]), abs(first_255_x_point - far_xrange[1]))\n",
    "    middle_finger_sp = (int((first_255_x_point - sub*1.5)), int(first_255_y_point*0.85))\n",
    "    middle_finger_ep = (int((first_255_x_point + sub*1.5)), int(far_yrange[0]*1.05))\n",
    "\n",
    "    # # 새끼손가락 좌표\n",
    "    # little_finger_sp = (int(min(end_xrange)*0.7), int(end_yrange[end_xrange.index(min(end_xrange[0:4]))]*0.9))\n",
    "    # little_finger_ep = (int(min(far_xrange[0:4])*0.95), int(far_yrange[far_xrange.index(min(far_xrange[0:4]))]*1.05))\n",
    "\n",
    "    #엄지손가락 좌표\n",
    "    thumb_sp = (int(max(far_xrange[0:4])*1.05), int(start_yrange[start_xrange.index(max(start_xrange))]*0.95))\n",
    "    thumb_ep = (int(max(start_xrange)*1.05), int(max(far_yrange)*0.9))\n",
    "    \n",
    "    optimized_imgs = crop_img(img0,(carpus_sp,carpus_ep), (four_sp, four_ep), (middle_finger_sp,middle_finger_ep), (thumb_sp, thumb_ep))\n",
    "    \n",
    "    row1 = np.vstack((optimized_imgs[0], optimized_imgs[1]))\n",
    "    row2 = np.vstack((optimized_imgs[2], optimized_imgs[3]))\n",
    "\n",
    "    combined_image = np.hstack((row1, row2))\n",
    "    combined_image = cv2.resize(combined_image, (256, 256))\n",
    "\n",
    "    X_data.append(combined_image)\n",
    "    y_data.append(data.boneage[k])\n",
    "    \n",
    "    # data augmentation - rotation\n",
    "    aug_rot_img = []\n",
    "    angle = np.random.randint(0, 90)\n",
    "    for crop_image in optimized_imgs:\n",
    "        # 이미지 중심을 계산\n",
    "        center = (crop_image.shape[1] // 2, crop_image.shape[0] // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "        # 회전된 이미지의 경계가 잘리지 않도록 출력 이미지의 크기 조정\n",
    "        cos = np.abs(rotation_matrix[0, 0])\n",
    "        sin = np.abs(rotation_matrix[0, 1])\n",
    "\n",
    "        # 새로운 경계 차원 계산\n",
    "        new_width = int((crop_image.shape[0] * sin) + (crop_image.shape[1] * cos))\n",
    "        new_height = int((crop_image.shape[0] * cos) + (crop_image.shape[1] * sin))\n",
    "\n",
    "        # 변환 행렬의 이동 부분 조정\n",
    "        rotation_matrix[0, 2] += (new_width / 2) - center[0]\n",
    "        rotation_matrix[1, 2] += (new_height / 2) - center[1]\n",
    "\n",
    "        # 회전된 이미지 얻기\n",
    "        rotated_img = cv2.warpAffine(crop_image, rotation_matrix, (new_width, new_height))\n",
    "        rotated_img = cv2.resize(rotated_img, (600, 600))\n",
    "        aug_rot_img.append(rotated_img)\n",
    "        \n",
    "    row1 = np.vstack((aug_rot_img[0], aug_rot_img[1]))\n",
    "    row2 = np.vstack((aug_rot_img[2], aug_rot_img[3]))\n",
    "\n",
    "    combined_image_rot = np.hstack((row1, row2))\n",
    "    combined_image_rot = cv2.resize(combined_image_rot, (256, 256))\n",
    "    \n",
    "    X_aug_rot.append(combined_image_rot)\n",
    "    y_aug_rot.append(data.boneage[k])\n",
    "    \n",
    "    # data augmentation - add noise\n",
    "    aug_noise_img = []\n",
    "    sigma = np.random.randint(10, 50)\n",
    "    for crop_image in optimized_imgs:\n",
    "        row, col = crop_image.shape\n",
    "        \n",
    "        # 노이즈 강도 조정\n",
    "        gaussian = np.random.normal(0, sigma, (row, col))\n",
    "        \n",
    "        # 노이즈 추가된 이미지 얻기\n",
    "        noisy_image = np.clip(crop_image + gaussian, 0, 255)\n",
    "        aug_noise_img.append(noisy_image)\n",
    "        \n",
    "    row1 = np.vstack((aug_noise_img[0], aug_noise_img[1]))\n",
    "    row2 = np.vstack((aug_noise_img[2], aug_noise_img[3]))\n",
    "\n",
    "    combined_image_noise = np.hstack((row1, row2))\n",
    "    combined_image_noise = cv2.resize(combined_image_noise, (256, 256))\n",
    "    \n",
    "    X_aug_noise.append(combined_image_noise)\n",
    "    y_aug_noise.append(data.boneage[k])\n",
    "    \n",
    "    # # data augmentation - resorting\n",
    "    # row1 = np.vstack((optimized_imgs[3], optimized_imgs[1]))\n",
    "    # row2 = np.vstack((optimized_imgs[2], optimized_imgs[0]))\n",
    "\n",
    "    # combined_image_resort = np.hstack((row1, row2))\n",
    "    # combined_image_resort = cv2.resize(combined_image_resort, (256, 256))\n",
    "\n",
    "    # X_aug_resort.append(combined_image_resort)\n",
    "    # y_aug_resort.append(data.boneage[k])\n",
    "    \n",
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "X_aug_rot = np.array(X_aug_rot)\n",
    "y_aug_rot = np.array(y_aug_rot)\n",
    "X_aug_noise = np.array(X_aug_noise)\n",
    "y_aug_noise = np.array(y_aug_noise)\n",
    "# X_aug_resort = np.array(X_aug_resort)\n",
    "# y_aug_resort = np.array(y_aug_resort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 생성 - Attention-Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 07:28:18.139586: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-05 07:28:18.139640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-05 07:28:18.141174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-05 07:28:18.148860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-05 07:28:19.069090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separable 합성곱 함수\n",
    "def separable_conv(x, inchannel,outchannel):\n",
    "  x = keras.layers.Conv2D(inchannel, (3,3), strides=1, padding=\"same\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Conv2D(outchannel, (1,1), strides=1, padding=\"same\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resiual_units 함수 \n",
    "def resiual_units(input_x):\n",
    "  x = keras.layers.ReLU()(input_x)\n",
    "  x = separable_conv(x,x.shape[-1],128)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  x = separable_conv(x,x.shape[-1],256)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "  x = keras.layers.ReLU()(x)\n",
    "  x = separable_conv(x,x.shape[-1],512)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  \n",
    "  input_x = keras.layers.Add()([x,input_x])\n",
    "\n",
    "  return input_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model middle_flow 함수\n",
    "def middle_flow(input_x):\n",
    "  #encoder\n",
    "  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(input_x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.MaxPool2D((2,2),padding=\"same\")(x)\n",
    "  x = resiual_units(x)\n",
    "  \n",
    "  #decoder\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "  x = resiual_units(x)\n",
    "  x = keras.layers.UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "  \n",
    "  x = separable_conv(x,x.shape[-1],512)\n",
    "  x = separable_conv(x,x.shape[-1],512) \n",
    "  \n",
    "  #sigmoid \n",
    "  x = keras.activations.sigmoid(x)\n",
    "  x = keras.layers.Multiply()([input_x,x])\n",
    "  x = keras.layers.Add()([input_x,x])\n",
    "\n",
    "  x = resiual_units(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#골연령 측정 모델\n",
    "# entry flow model\n",
    "input = keras.Input(shape=(256,256,1))\n",
    "x = keras.layers.Conv2D(32, (3,3), strides = 2)(input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.Conv2D(64, (3,3), strides=1)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "#첫번째\n",
    "x1 = keras.layers.Conv2D(128,(1,1),strides=2)(x) \n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],128)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],128)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Add()([x,x1])\n",
    "\n",
    "#2번째\n",
    "x1 = keras.layers.Conv2D(512,(1,1),strides=2)(x)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],512)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],512)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Add()([x,x1])\n",
    "\n",
    "\n",
    "#middle flow model\n",
    "x = middle_flow(x)\n",
    "\n",
    "\n",
    "#exit flow model\n",
    "x1 = keras.layers.Conv2D(1024,(1,1),strides=2)(x)\n",
    "\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = separable_conv(x,x.shape[-1],728)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = separable_conv(x,x.shape[-1],1024)\n",
    "x = keras.layers.MaxPool2D((2,2),2,padding=\"same\")(x)\n",
    "\n",
    "x = keras.layers.Add()([x,x1])\n",
    "\n",
    "\n",
    "x = separable_conv(x,x.shape[-1],1536)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = separable_conv(x,x.shape[-1],2048)\n",
    "x = keras.layers.ReLU()(x)\n",
    "\n",
    "x = keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "x = keras.layers.Dense(1000,activation='relu')(x)\n",
    "x = keras.layers.Dense(256,activation='relu')(x)\n",
    "x = keras.layers.Dense(1)(x)\n",
    "\n",
    "model = keras.models.Model(input,x)\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mae','mse'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiuser/.conda/envs/junoflow/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('./tjnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, 127, 127, 32)         320       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, 127, 127, 32)         128       ['conv2d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)             (None, 127, 127, 32)         0         ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, 125, 125, 64)         18496     ['re_lu_31[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, 125, 125, 64)         256       ['conv2d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)             (None, 125, 125, 64)         0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, 125, 125, 64)         36928     ['re_lu_32[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, 125, 125, 64)         256       ['conv2d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, 125, 125, 128)        8320      ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, 125, 125, 128)        512       ['conv2d_71[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)             (None, 125, 125, 128)        0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, 125, 125, 128)        147584    ['re_lu_33[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, 125, 125, 128)        512       ['conv2d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, 125, 125, 128)        16512     ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, 125, 125, 128)        512       ['conv2d_73[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)             (None, 125, 125, 128)        0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, 63, 63, 128)          8320      ['re_lu_32[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 63, 63, 128)          0         ['re_lu_34[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, 63, 63, 128)          512       ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 63, 63, 128)          0         ['max_pooling2d_6[0][0]',     \n",
      "                                                                     'batch_normalization_89[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (None, 63, 63, 128)          147584    ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 63, 63, 128)          512       ['conv2d_75[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)          (None, 63, 63, 512)          66048     ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, 63, 63, 512)          2048      ['conv2d_76[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)             (None, 63, 63, 512)          0         ['batch_normalization_96[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)          (None, 63, 63, 512)          2359808   ['re_lu_35[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, 63, 63, 512)          2048      ['conv2d_77[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)          (None, 63, 63, 512)          262656    ['batch_normalization_97[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, 63, 63, 512)          2048      ['conv2d_78[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)             (None, 63, 63, 512)          0         ['batch_normalization_98[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, 32, 32, 512)          66048     ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 32, 32, 512)          0         ['re_lu_36[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 32, 32, 512)          2048      ['conv2d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 32, 32, 512)          0         ['max_pooling2d_7[0][0]',     \n",
      "                                                                     'batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 512)          0         ['add_12[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)             (None, 16, 16, 512)          0         ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)          (None, 16, 16, 512)          2359808   ['re_lu_37[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (None, 16, 16, 512)          2048      ['conv2d_79[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)          (None, 16, 16, 128)          65664     ['batch_normalization_99[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, 16, 16, 128)          512       ['conv2d_80[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, 16, 16, 128)          512       ['batch_normalization_100[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)             (None, 16, 16, 128)          0         ['batch_normalization_101[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)          (None, 16, 16, 128)          147584    ['re_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, 16, 16, 128)          512       ['conv2d_81[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)          (None, 16, 16, 256)          33024     ['batch_normalization_102[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (None, 16, 16, 256)          1024      ['conv2d_82[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (None, 16, 16, 256)          1024      ['batch_normalization_103[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)             (None, 16, 16, 256)          0         ['batch_normalization_104[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (None, 16, 16, 256)          590080    ['re_lu_39[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, 16, 16, 256)          1024      ['conv2d_83[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)          (None, 16, 16, 512)          131584    ['batch_normalization_105[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (None, 16, 16, 512)          2048      ['conv2d_84[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (None, 16, 16, 512)          2048      ['batch_normalization_106[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 16, 16, 512)          0         ['batch_normalization_107[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 8, 8, 512)            0         ['add_13[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)             (None, 8, 8, 512)            0         ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (None, 8, 8, 512)            2359808   ['re_lu_40[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_108 (B  (None, 8, 8, 512)            2048      ['conv2d_85[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)          (None, 8, 8, 128)            65664     ['batch_normalization_108[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_109 (B  (None, 8, 8, 128)            512       ['conv2d_86[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_110 (B  (None, 8, 8, 128)            512       ['batch_normalization_109[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)             (None, 8, 8, 128)            0         ['batch_normalization_110[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 8, 8, 128)            147584    ['re_lu_41[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_111 (B  (None, 8, 8, 128)            512       ['conv2d_87[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, 8, 8, 256)            33024     ['batch_normalization_111[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_112 (B  (None, 8, 8, 256)            1024      ['conv2d_88[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_113 (B  (None, 8, 8, 256)            1024      ['batch_normalization_112[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)             (None, 8, 8, 256)            0         ['batch_normalization_113[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, 8, 8, 256)            590080    ['re_lu_42[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_114 (B  (None, 8, 8, 256)            1024      ['conv2d_89[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)          (None, 8, 8, 512)            131584    ['batch_normalization_114[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_115 (B  (None, 8, 8, 512)            2048      ['conv2d_90[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_116 (B  (None, 8, 8, 512)            2048      ['batch_normalization_115[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 8, 8, 512)            0         ['batch_normalization_116[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 4, 4, 512)            0         ['add_14[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)             (None, 4, 4, 512)            0         ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (None, 4, 4, 512)            2359808   ['re_lu_43[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_117 (B  (None, 4, 4, 512)            2048      ['conv2d_91[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (None, 4, 4, 128)            65664     ['batch_normalization_117[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_118 (B  (None, 4, 4, 128)            512       ['conv2d_92[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_119 (B  (None, 4, 4, 128)            512       ['batch_normalization_118[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)             (None, 4, 4, 128)            0         ['batch_normalization_119[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)          (None, 4, 4, 128)            147584    ['re_lu_44[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_120 (B  (None, 4, 4, 128)            512       ['conv2d_93[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)          (None, 4, 4, 256)            33024     ['batch_normalization_120[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_121 (B  (None, 4, 4, 256)            1024      ['conv2d_94[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_122 (B  (None, 4, 4, 256)            1024      ['batch_normalization_121[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)             (None, 4, 4, 256)            0         ['batch_normalization_122[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)          (None, 4, 4, 256)            590080    ['re_lu_45[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_123 (B  (None, 4, 4, 256)            1024      ['conv2d_95[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)          (None, 4, 4, 512)            131584    ['batch_normalization_123[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_124 (B  (None, 4, 4, 512)            2048      ['conv2d_96[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_125 (B  (None, 4, 4, 512)            2048      ['batch_normalization_124[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 4, 4, 512)            0         ['batch_normalization_125[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)             (None, 4, 4, 512)            0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)          (None, 4, 4, 512)            2359808   ['re_lu_46[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_126 (B  (None, 4, 4, 512)            2048      ['conv2d_97[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (None, 4, 4, 128)            65664     ['batch_normalization_126[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_127 (B  (None, 4, 4, 128)            512       ['conv2d_98[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_128 (B  (None, 4, 4, 128)            512       ['batch_normalization_127[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)             (None, 4, 4, 128)            0         ['batch_normalization_128[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (None, 4, 4, 128)            147584    ['re_lu_47[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_129 (B  (None, 4, 4, 128)            512       ['conv2d_99[0][0]']           \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (None, 4, 4, 256)            33024     ['batch_normalization_129[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_130 (B  (None, 4, 4, 256)            1024      ['conv2d_100[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_131 (B  (None, 4, 4, 256)            1024      ['batch_normalization_130[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)             (None, 4, 4, 256)            0         ['batch_normalization_131[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (None, 4, 4, 256)            590080    ['re_lu_48[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_132 (B  (None, 4, 4, 256)            1024      ['conv2d_101[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (None, 4, 4, 512)            131584    ['batch_normalization_132[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_133 (B  (None, 4, 4, 512)            2048      ['conv2d_102[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_134 (B  (None, 4, 4, 512)            2048      ['batch_normalization_133[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 4, 4, 512)            0         ['batch_normalization_134[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_15[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 8, 8, 512)            0         ['add_16[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)             (None, 8, 8, 512)            0         ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)         (None, 8, 8, 512)            2359808   ['re_lu_49[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_135 (B  (None, 8, 8, 512)            2048      ['conv2d_103[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)         (None, 8, 8, 128)            65664     ['batch_normalization_135[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_136 (B  (None, 8, 8, 128)            512       ['conv2d_104[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_137 (B  (None, 8, 8, 128)            512       ['batch_normalization_136[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)             (None, 8, 8, 128)            0         ['batch_normalization_137[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)         (None, 8, 8, 128)            147584    ['re_lu_50[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_138 (B  (None, 8, 8, 128)            512       ['conv2d_105[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)         (None, 8, 8, 256)            33024     ['batch_normalization_138[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_139 (B  (None, 8, 8, 256)            1024      ['conv2d_106[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_140 (B  (None, 8, 8, 256)            1024      ['batch_normalization_139[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)             (None, 8, 8, 256)            0         ['batch_normalization_140[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)         (None, 8, 8, 256)            590080    ['re_lu_51[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_141 (B  (None, 8, 8, 256)            1024      ['conv2d_107[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)         (None, 8, 8, 512)            131584    ['batch_normalization_141[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_142 (B  (None, 8, 8, 512)            2048      ['conv2d_108[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_143 (B  (None, 8, 8, 512)            2048      ['batch_normalization_142[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 8, 8, 512)            0         ['batch_normalization_143[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 16, 16, 512)          0         ['add_17[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)             (None, 16, 16, 512)          0         ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)         (None, 16, 16, 512)          2359808   ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (None, 16, 16, 512)          2048      ['conv2d_109[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)         (None, 16, 16, 128)          65664     ['batch_normalization_144[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (None, 16, 16, 128)          512       ['conv2d_110[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (None, 16, 16, 128)          512       ['batch_normalization_145[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)             (None, 16, 16, 128)          0         ['batch_normalization_146[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)         (None, 16, 16, 128)          147584    ['re_lu_53[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (None, 16, 16, 128)          512       ['conv2d_111[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, 16, 16, 256)          33024     ['batch_normalization_147[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (None, 16, 16, 256)          1024      ['conv2d_112[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (None, 16, 16, 256)          1024      ['batch_normalization_148[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)             (None, 16, 16, 256)          0         ['batch_normalization_149[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, 16, 16, 256)          590080    ['re_lu_54[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (None, 16, 16, 256)          1024      ['conv2d_113[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, 16, 16, 512)          131584    ['batch_normalization_150[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (None, 16, 16, 512)          2048      ['conv2d_114[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (None, 16, 16, 512)          2048      ['batch_normalization_151[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 16, 16, 512)          0         ['batch_normalization_152[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 32, 32, 512)          0         ['add_18[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, 32, 32, 512)          2359808   ['up_sampling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (None, 32, 32, 512)          2048      ['conv2d_115[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, 32, 32, 512)          262656    ['batch_normalization_153[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_154 (B  (None, 32, 32, 512)          2048      ['conv2d_116[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, 32, 32, 512)          2359808   ['batch_normalization_154[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_155 (B  (None, 32, 32, 512)          2048      ['conv2d_117[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, 32, 32, 512)          262656    ['batch_normalization_155[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_156 (B  (None, 32, 32, 512)          2048      ['conv2d_118[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.sigmoid_1 (TFOpLam  (None, 32, 32, 512)          0         ['batch_normalization_156[0][0\n",
      " bda)                                                               ]']                           \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 32, 32, 512)          0         ['add_12[0][0]',              \n",
      "                                                                     'tf.math.sigmoid_1[0][0]']   \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 32, 32, 512)          0         ['add_12[0][0]',              \n",
      "                                                                     'multiply_1[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)             (None, 32, 32, 512)          0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, 32, 32, 512)          2359808   ['re_lu_55[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_157 (B  (None, 32, 32, 512)          2048      ['conv2d_119[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, 32, 32, 128)          65664     ['batch_normalization_157[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_158 (B  (None, 32, 32, 128)          512       ['conv2d_120[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_159 (B  (None, 32, 32, 128)          512       ['batch_normalization_158[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)             (None, 32, 32, 128)          0         ['batch_normalization_159[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, 32, 32, 128)          147584    ['re_lu_56[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_160 (B  (None, 32, 32, 128)          512       ['conv2d_121[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (None, 32, 32, 256)          33024     ['batch_normalization_160[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_161 (B  (None, 32, 32, 256)          1024      ['conv2d_122[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_162 (B  (None, 32, 32, 256)          1024      ['batch_normalization_161[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)             (None, 32, 32, 256)          0         ['batch_normalization_162[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, 32, 32, 256)          590080    ['re_lu_57[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_163 (B  (None, 32, 32, 256)          1024      ['conv2d_123[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, 32, 32, 512)          131584    ['batch_normalization_163[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_164 (B  (None, 32, 32, 512)          2048      ['conv2d_124[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_165 (B  (None, 32, 32, 512)          2048      ['batch_normalization_164[0][0\n",
      " atchNormalization)                                                 ]']                           \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 32, 32, 512)          0         ['batch_normalization_165[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_19[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)             (None, 32, 32, 512)          0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, 32, 32, 512)          2359808   ['re_lu_58[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_166 (B  (None, 32, 32, 512)          2048      ['conv2d_126[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, 32, 32, 728)          373464    ['batch_normalization_166[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_167 (B  (None, 32, 32, 728)          2912      ['conv2d_127[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)             (None, 32, 32, 728)          0         ['batch_normalization_167[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, 32, 32, 728)          4770584   ['re_lu_59[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_168 (B  (None, 32, 32, 728)          2912      ['conv2d_128[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, 32, 32, 1024)         746496    ['batch_normalization_168[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_169 (B  (None, 32, 32, 1024)         4096      ['conv2d_129[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 16, 16, 1024)         0         ['batch_normalization_169[0][0\n",
      " ng2D)                                                              ]']                           \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, 16, 16, 1024)         525312    ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 16, 16, 1024)         0         ['max_pooling2d_11[0][0]',    \n",
      "                                                                     'conv2d_125[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, 16, 16, 1024)         9438208   ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_170 (B  (None, 16, 16, 1024)         4096      ['conv2d_130[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, 16, 16, 1536)         1574400   ['batch_normalization_170[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_171 (B  (None, 16, 16, 1536)         6144      ['conv2d_131[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)             (None, 16, 16, 1536)         0         ['batch_normalization_171[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (None, 16, 16, 1536)         2123520   ['re_lu_60[0][0]']            \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " batch_normalization_172 (B  (None, 16, 16, 1536)         6144      ['conv2d_132[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (None, 16, 16, 2048)         3147776   ['batch_normalization_172[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_173 (B  (None, 16, 16, 2048)         8192      ['conv2d_133[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)             (None, 16, 16, 2048)         0         ['batch_normalization_173[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 2048)                 0         ['re_lu_61[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1000)                 2049000   ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 256)                  256256    ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    257       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78285913 (298.64 MB)\n",
      "Trainable params: 78220217 (298.39 MB)\n",
      "Non-trainable params: 65696 (256.62 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7:2:1 == train:valid:test \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data.reshape(1234, 256, 256, 1), y_data, \n",
    "#                                                   random_state=42, test_size=0.2)\n",
    "\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state=42, test_size = 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data.reshape(1234, 256, 256, 1), \n",
    "                                                    y_data, random_state=42, test_size=0.2)\n",
    "\n",
    "X_rot_train, X_rot_test, y_rot_train, y_rot_test = train_test_split(X_aug_rot.reshape(1234, 256, 256, 1), \n",
    "                                                                    y_data, random_state=42, test_size=0.2)\n",
    "\n",
    "X_noise_train, X_noise_test, y_noise_train, y_noise_test = train_test_split(X_aug_noise.reshape(1234, 256, 256, 1), \n",
    "                                                                            y_data, random_state=42, test_size=0.2)\n",
    "\n",
    "X_resort_train, X_resort_test, y_resort_train, y_resort_test = train_test_split(X_aug_resort.reshape(1234, 256, 256, 1), \n",
    "                                                                            y_data, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 증강한 데이터 비율을 낮추기 - 원본 데이터의 정보를 더 많이 반영하기 위해 => 안하는게 더 정확했음\n",
    "# X_rot_train, X_rot_low, y_rot_train, y_rot_low = train_test_split(X_rot_train, y_rot_train, random_state=43, test_size=0.5)\n",
    "# X_noise_train, X_noise_low, y_noise_train, y_noise_low = train_test_split(X_noise_train, y_noise_train, random_state=44, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug_data = np.concatenate((X_train, X_rot_train, X_noise_train, X_resort_train), axis = 0)\n",
    "y_aug_data = np.concatenate((y_train, y_rot_train, y_noise_train, y_resort_train), axis = 0)\n",
    "\n",
    "X_aug_train, X_aug_val, y_aug_train, y_aug_val = train_test_split(X_aug_data, y_aug_data, random_state=42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filename = 'checkpoint-150-epochs-8-batchs.h5'\n",
    "checkpoint = ModelCheckpoint(filename, mointor='val_loss', verbose=1, \n",
    "                             save_best_only = True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./checkpoint-50-epochs-8-batchs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 2.7902 - mae: 2.7902 - mse: 13.3232\n",
      "Epoch 1: val_loss improved from inf to 57.55753, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 222s 495ms/step - loss: 2.7902 - mae: 2.7902 - mse: 13.3232 - val_loss: 57.5575 - val_mae: 57.5575 - val_mse: 3678.3059\n",
      "Epoch 2/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.9913 - mae: 1.9913 - mse: 6.6902\n",
      "Epoch 2: val_loss improved from 57.55753 to 1.70929, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 188s 476ms/step - loss: 1.9913 - mae: 1.9913 - mse: 6.6902 - val_loss: 1.7093 - val_mae: 1.7093 - val_mse: 4.7311\n",
      "Epoch 3/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.7796 - mae: 1.7796 - mse: 5.2813\n",
      "Epoch 3: val_loss did not improve from 1.70929\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 1.7796 - mae: 1.7796 - mse: 5.2813 - val_loss: 9.6003 - val_mae: 9.6003 - val_mse: 130.2802\n",
      "Epoch 4/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.6666 - mae: 1.6666 - mse: 4.7645\n",
      "Epoch 4: val_loss did not improve from 1.70929\n",
      "395/395 [==============================] - 187s 472ms/step - loss: 1.6666 - mae: 1.6666 - mse: 4.7645 - val_loss: 3.2143 - val_mae: 3.2143 - val_mse: 16.3503\n",
      "Epoch 5/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.6377 - mae: 1.6377 - mse: 4.5172\n",
      "Epoch 5: val_loss did not improve from 1.70929\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 1.6377 - mae: 1.6377 - mse: 4.5172 - val_loss: 2.2435 - val_mae: 2.2435 - val_mse: 7.2377\n",
      "Epoch 6/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.4233 - mae: 1.4233 - mse: 3.4312\n",
      "Epoch 6: val_loss improved from 1.70929 to 1.49307, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 186s 472ms/step - loss: 1.4233 - mae: 1.4233 - mse: 3.4312 - val_loss: 1.4931 - val_mae: 1.4931 - val_mse: 3.7905\n",
      "Epoch 7/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.3336 - mae: 1.3336 - mse: 3.0146\n",
      "Epoch 7: val_loss did not improve from 1.49307\n",
      "395/395 [==============================] - 189s 479ms/step - loss: 1.3336 - mae: 1.3336 - mse: 3.0146 - val_loss: 6.4078 - val_mae: 6.4078 - val_mse: 55.4798\n",
      "Epoch 8/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.2724 - mae: 1.2724 - mse: 2.7372\n",
      "Epoch 8: val_loss did not improve from 1.49307\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 1.2724 - mae: 1.2724 - mse: 2.7372 - val_loss: 2.5652 - val_mae: 2.5652 - val_mse: 8.6520\n",
      "Epoch 9/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.2249 - mae: 1.2249 - mse: 2.4544\n",
      "Epoch 9: val_loss did not improve from 1.49307\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 1.2249 - mae: 1.2249 - mse: 2.4544 - val_loss: 1.5465 - val_mae: 1.5465 - val_mse: 4.7426\n",
      "Epoch 10/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.1683 - mae: 1.1683 - mse: 2.2842\n",
      "Epoch 10: val_loss did not improve from 1.49307\n",
      "395/395 [==============================] - 194s 492ms/step - loss: 1.1683 - mae: 1.1683 - mse: 2.2842 - val_loss: 1.5153 - val_mae: 1.5153 - val_mse: 3.3959\n",
      "Epoch 11/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.1101 - mae: 1.1101 - mse: 2.0821\n",
      "Epoch 11: val_loss improved from 1.49307 to 1.01659, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 196s 497ms/step - loss: 1.1101 - mae: 1.1101 - mse: 2.0821 - val_loss: 1.0166 - val_mae: 1.0166 - val_mse: 1.7698\n",
      "Epoch 12/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.1372 - mae: 1.1372 - mse: 2.1272\n",
      "Epoch 12: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 190s 480ms/step - loss: 1.1372 - mae: 1.1372 - mse: 2.1272 - val_loss: 2.2974 - val_mae: 2.2974 - val_mse: 7.8489\n",
      "Epoch 13/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.0253 - mae: 1.0253 - mse: 1.7842\n",
      "Epoch 13: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 183s 462ms/step - loss: 1.0253 - mae: 1.0253 - mse: 1.7842 - val_loss: 1.0661 - val_mae: 1.0661 - val_mse: 1.9245\n",
      "Epoch 14/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.0509 - mae: 1.0509 - mse: 1.8915\n",
      "Epoch 14: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 1.0509 - mae: 1.0509 - mse: 1.8915 - val_loss: 1.9931 - val_mae: 1.9931 - val_mse: 5.1952\n",
      "Epoch 15/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 1.0222 - mae: 1.0222 - mse: 1.8448\n",
      "Epoch 15: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 1.0222 - mae: 1.0222 - mse: 1.8448 - val_loss: 1.8115 - val_mae: 1.8115 - val_mse: 5.2085\n",
      "Epoch 16/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.9761 - mae: 0.9761 - mse: 1.6392\n",
      "Epoch 16: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 0.9761 - mae: 0.9761 - mse: 1.6392 - val_loss: 3.2452 - val_mae: 3.2452 - val_mse: 14.3514\n",
      "Epoch 17/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.9233 - mae: 0.9233 - mse: 1.4340\n",
      "Epoch 17: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.9233 - mae: 0.9233 - mse: 1.4340 - val_loss: 4.5572 - val_mae: 4.5572 - val_mse: 29.9347\n",
      "Epoch 18/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.9487 - mae: 0.9487 - mse: 1.5199\n",
      "Epoch 18: val_loss did not improve from 1.01659\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.9487 - mae: 0.9487 - mse: 1.5199 - val_loss: 1.3409 - val_mae: 1.3409 - val_mse: 2.6813\n",
      "Epoch 19/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.8692 - mae: 0.8692 - mse: 1.2577\n",
      "Epoch 19: val_loss improved from 1.01659 to 0.80122, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 188s 476ms/step - loss: 0.8692 - mae: 0.8692 - mse: 1.2577 - val_loss: 0.8012 - val_mae: 0.8012 - val_mse: 1.1058\n",
      "Epoch 20/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.8882 - mae: 0.8882 - mse: 1.3742\n",
      "Epoch 20: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.8882 - mae: 0.8882 - mse: 1.3742 - val_loss: 2.4214 - val_mae: 2.4214 - val_mse: 7.6428\n",
      "Epoch 21/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.7964 - mae: 0.7964 - mse: 1.1095\n",
      "Epoch 21: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 186s 472ms/step - loss: 0.7964 - mae: 0.7964 - mse: 1.1095 - val_loss: 1.1824 - val_mae: 1.1824 - val_mse: 2.2924\n",
      "Epoch 22/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.8149 - mae: 0.8149 - mse: 1.1583\n",
      "Epoch 22: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 184s 466ms/step - loss: 0.8149 - mae: 0.8149 - mse: 1.1583 - val_loss: 0.9409 - val_mae: 0.9409 - val_mse: 1.4443\n",
      "Epoch 23/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.7865 - mae: 0.7865 - mse: 1.0687\n",
      "Epoch 23: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.7865 - mae: 0.7865 - mse: 1.0687 - val_loss: 1.0674 - val_mae: 1.0674 - val_mse: 1.8177\n",
      "Epoch 24/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.7836 - mae: 0.7836 - mse: 1.1007\n",
      "Epoch 24: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 193s 488ms/step - loss: 0.7836 - mae: 0.7836 - mse: 1.1007 - val_loss: 1.1083 - val_mae: 1.1083 - val_mse: 2.1103\n",
      "Epoch 25/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.7919 - mae: 0.7919 - mse: 1.0681\n",
      "Epoch 25: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.7919 - mae: 0.7919 - mse: 1.0681 - val_loss: 0.9364 - val_mae: 0.9364 - val_mse: 1.4172\n",
      "Epoch 26/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.7543 - mae: 0.7543 - mse: 0.9760\n",
      "Epoch 26: val_loss did not improve from 0.80122\n",
      "395/395 [==============================] - 187s 474ms/step - loss: 0.7543 - mae: 0.7543 - mse: 0.9760 - val_loss: 2.5735 - val_mae: 2.5735 - val_mse: 8.3378\n",
      "Epoch 27/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6952 - mae: 0.6952 - mse: 0.8530\n",
      "Epoch 27: val_loss improved from 0.80122 to 0.77591, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 188s 475ms/step - loss: 0.6952 - mae: 0.6952 - mse: 0.8530 - val_loss: 0.7759 - val_mae: 0.7759 - val_mse: 1.0638\n",
      "Epoch 28/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6746 - mae: 0.6746 - mse: 0.7911\n",
      "Epoch 28: val_loss did not improve from 0.77591\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.6746 - mae: 0.6746 - mse: 0.7911 - val_loss: 0.8670 - val_mae: 0.8670 - val_mse: 1.3242\n",
      "Epoch 29/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.7058 - mae: 0.7058 - mse: 0.8714\n",
      "Epoch 29: val_loss did not improve from 0.77591\n",
      "395/395 [==============================] - 185s 468ms/step - loss: 0.7058 - mae: 0.7058 - mse: 0.8714 - val_loss: 1.2747 - val_mae: 1.2747 - val_mse: 2.4620\n",
      "Epoch 30/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6762 - mae: 0.6762 - mse: 0.7777\n",
      "Epoch 30: val_loss did not improve from 0.77591\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.6762 - mae: 0.6762 - mse: 0.7777 - val_loss: 2.5300 - val_mae: 2.5300 - val_mse: 7.7876\n",
      "Epoch 31/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6844 - mae: 0.6844 - mse: 0.7896\n",
      "Epoch 31: val_loss did not improve from 0.77591\n",
      "395/395 [==============================] - 195s 493ms/step - loss: 0.6844 - mae: 0.6844 - mse: 0.7896 - val_loss: 1.3530 - val_mae: 1.3530 - val_mse: 2.6680\n",
      "Epoch 32/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6378 - mae: 0.6378 - mse: 0.7012\n",
      "Epoch 32: val_loss improved from 0.77591 to 0.71651, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 190s 482ms/step - loss: 0.6378 - mae: 0.6378 - mse: 0.7012 - val_loss: 0.7165 - val_mae: 0.7165 - val_mse: 0.8983\n",
      "Epoch 33/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6050 - mae: 0.6050 - mse: 0.6464\n",
      "Epoch 33: val_loss improved from 0.71651 to 0.69849, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 190s 481ms/step - loss: 0.6050 - mae: 0.6050 - mse: 0.6464 - val_loss: 0.6985 - val_mae: 0.6985 - val_mse: 0.8692\n",
      "Epoch 34/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6142 - mae: 0.6142 - mse: 0.6553\n",
      "Epoch 34: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 185s 467ms/step - loss: 0.6142 - mae: 0.6142 - mse: 0.6553 - val_loss: 1.6292 - val_mae: 1.6292 - val_mse: 3.6069\n",
      "Epoch 35/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6213 - mae: 0.6213 - mse: 0.6631\n",
      "Epoch 35: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.6213 - mae: 0.6213 - mse: 0.6631 - val_loss: 1.0714 - val_mae: 1.0714 - val_mse: 1.5976\n",
      "Epoch 36/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5635 - mae: 0.5635 - mse: 0.5504\n",
      "Epoch 36: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 184s 467ms/step - loss: 0.5635 - mae: 0.5635 - mse: 0.5504 - val_loss: 1.9413 - val_mae: 1.9413 - val_mse: 5.4299\n",
      "Epoch 37/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.6028 - mae: 0.6028 - mse: 0.6160\n",
      "Epoch 37: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 184s 467ms/step - loss: 0.6028 - mae: 0.6028 - mse: 0.6160 - val_loss: 1.1309 - val_mae: 1.1309 - val_mse: 1.8061\n",
      "Epoch 38/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5581 - mae: 0.5581 - mse: 0.5338\n",
      "Epoch 38: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 184s 466ms/step - loss: 0.5581 - mae: 0.5581 - mse: 0.5338 - val_loss: 1.3129 - val_mae: 1.3129 - val_mse: 2.4513\n",
      "Epoch 39/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5583 - mae: 0.5583 - mse: 0.5284\n",
      "Epoch 39: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 184s 467ms/step - loss: 0.5583 - mae: 0.5583 - mse: 0.5284 - val_loss: 0.9121 - val_mae: 0.9121 - val_mse: 1.3081\n",
      "Epoch 40/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5631 - mae: 0.5631 - mse: 0.5438\n",
      "Epoch 40: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.5631 - mae: 0.5631 - mse: 0.5438 - val_loss: 0.7446 - val_mae: 0.7446 - val_mse: 0.9583\n",
      "Epoch 41/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5211 - mae: 0.5211 - mse: 0.4643\n",
      "Epoch 41: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 185s 470ms/step - loss: 0.5211 - mae: 0.5211 - mse: 0.4643 - val_loss: 0.8194 - val_mae: 0.8194 - val_mse: 1.0226\n",
      "Epoch 42/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5373 - mae: 0.5373 - mse: 0.4976\n",
      "Epoch 42: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 182s 461ms/step - loss: 0.5373 - mae: 0.5373 - mse: 0.4976 - val_loss: 1.0983 - val_mae: 1.0983 - val_mse: 1.8093\n",
      "Epoch 43/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5207 - mae: 0.5207 - mse: 0.4740\n",
      "Epoch 43: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 183s 463ms/step - loss: 0.5207 - mae: 0.5207 - mse: 0.4740 - val_loss: 0.7054 - val_mae: 0.7054 - val_mse: 0.8693\n",
      "Epoch 44/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5129 - mae: 0.5129 - mse: 0.4485\n",
      "Epoch 44: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.5129 - mae: 0.5129 - mse: 0.4485 - val_loss: 0.7646 - val_mae: 0.7646 - val_mse: 1.0142\n",
      "Epoch 45/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5419 - mae: 0.5419 - mse: 0.5425\n",
      "Epoch 45: val_loss did not improve from 0.69849\n",
      "395/395 [==============================] - 183s 463ms/step - loss: 0.5419 - mae: 0.5419 - mse: 0.5425 - val_loss: 1.4767 - val_mae: 1.4767 - val_mse: 2.8384\n",
      "Epoch 46/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5047 - mae: 0.5047 - mse: 0.4305\n",
      "Epoch 46: val_loss improved from 0.69849 to 0.55447, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.5047 - mae: 0.5047 - mse: 0.4305 - val_loss: 0.5545 - val_mae: 0.5545 - val_mse: 0.6193\n",
      "Epoch 47/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5340 - mae: 0.5340 - mse: 0.4801\n",
      "Epoch 47: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 192s 487ms/step - loss: 0.5340 - mae: 0.5340 - mse: 0.4801 - val_loss: 1.3444 - val_mae: 1.3444 - val_mse: 2.7542\n",
      "Epoch 48/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5142 - mae: 0.5142 - mse: 0.4565\n",
      "Epoch 48: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 196s 495ms/step - loss: 0.5142 - mae: 0.5142 - mse: 0.4565 - val_loss: 0.7619 - val_mae: 0.7619 - val_mse: 1.0044\n",
      "Epoch 49/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4872 - mae: 0.4872 - mse: 0.4167\n",
      "Epoch 49: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.4872 - mae: 0.4872 - mse: 0.4167 - val_loss: 1.0444 - val_mae: 1.0444 - val_mse: 1.5242\n",
      "Epoch 50/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4939 - mae: 0.4939 - mse: 0.4133\n",
      "Epoch 50: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.4939 - mae: 0.4939 - mse: 0.4133 - val_loss: 1.4221 - val_mae: 1.4221 - val_mse: 2.8721\n",
      "Epoch 51/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.5195 - mae: 0.5195 - mse: 0.4600\n",
      "Epoch 51: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.5195 - mae: 0.5195 - mse: 0.4600 - val_loss: 0.5801 - val_mae: 0.5801 - val_mse: 0.6269\n",
      "Epoch 52/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4840 - mae: 0.4840 - mse: 0.3969\n",
      "Epoch 52: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.4840 - mae: 0.4840 - mse: 0.3969 - val_loss: 0.6417 - val_mae: 0.6417 - val_mse: 0.7272\n",
      "Epoch 53/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4946 - mae: 0.4946 - mse: 0.4627\n",
      "Epoch 53: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.4946 - mae: 0.4946 - mse: 0.4627 - val_loss: 0.6868 - val_mae: 0.6868 - val_mse: 0.8320\n",
      "Epoch 54/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4518 - mae: 0.4518 - mse: 0.3435\n",
      "Epoch 54: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 0.4518 - mae: 0.4518 - mse: 0.3435 - val_loss: 0.6405 - val_mae: 0.6405 - val_mse: 0.7013\n",
      "Epoch 55/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4661 - mae: 0.4661 - mse: 0.3695\n",
      "Epoch 55: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 187s 474ms/step - loss: 0.4661 - mae: 0.4661 - mse: 0.3695 - val_loss: 0.7557 - val_mae: 0.7557 - val_mse: 0.9333\n",
      "Epoch 56/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4339 - mae: 0.4339 - mse: 0.3212\n",
      "Epoch 56: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 188s 477ms/step - loss: 0.4339 - mae: 0.4339 - mse: 0.3212 - val_loss: 0.7381 - val_mae: 0.7381 - val_mse: 0.9191\n",
      "Epoch 57/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4387 - mae: 0.4387 - mse: 0.3168\n",
      "Epoch 57: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 188s 476ms/step - loss: 0.4387 - mae: 0.4387 - mse: 0.3168 - val_loss: 1.2515 - val_mae: 1.2515 - val_mse: 2.0919\n",
      "Epoch 58/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4457 - mae: 0.4457 - mse: 0.3390\n",
      "Epoch 58: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 183s 464ms/step - loss: 0.4457 - mae: 0.4457 - mse: 0.3390 - val_loss: 0.5629 - val_mae: 0.5629 - val_mse: 0.5798\n",
      "Epoch 59/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4281 - mae: 0.4281 - mse: 0.3096\n",
      "Epoch 59: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 185s 467ms/step - loss: 0.4281 - mae: 0.4281 - mse: 0.3096 - val_loss: 0.5990 - val_mae: 0.5990 - val_mse: 0.6056\n",
      "Epoch 60/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4010 - mae: 0.4010 - mse: 0.2763\n",
      "Epoch 60: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 183s 464ms/step - loss: 0.4010 - mae: 0.4010 - mse: 0.2763 - val_loss: 0.6712 - val_mae: 0.6712 - val_mse: 0.7573\n",
      "Epoch 61/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4180 - mae: 0.4180 - mse: 0.2963\n",
      "Epoch 61: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 183s 463ms/step - loss: 0.4180 - mae: 0.4180 - mse: 0.2963 - val_loss: 0.6597 - val_mae: 0.6597 - val_mse: 0.7741\n",
      "Epoch 62/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4130 - mae: 0.4130 - mse: 0.2935\n",
      "Epoch 62: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 187s 472ms/step - loss: 0.4130 - mae: 0.4130 - mse: 0.2935 - val_loss: 0.5802 - val_mae: 0.5802 - val_mse: 0.6013\n",
      "Epoch 63/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4124 - mae: 0.4124 - mse: 0.2912\n",
      "Epoch 63: val_loss did not improve from 0.55447\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.4124 - mae: 0.4124 - mse: 0.2912 - val_loss: 0.5879 - val_mae: 0.5879 - val_mse: 0.6122\n",
      "Epoch 64/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4134 - mae: 0.4134 - mse: 0.2925\n",
      "Epoch 64: val_loss improved from 0.55447 to 0.53774, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 190s 480ms/step - loss: 0.4134 - mae: 0.4134 - mse: 0.2925 - val_loss: 0.5377 - val_mae: 0.5377 - val_mse: 0.5427\n",
      "Epoch 65/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3798 - mae: 0.3798 - mse: 0.2382\n",
      "Epoch 65: val_loss improved from 0.53774 to 0.52998, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 188s 475ms/step - loss: 0.3798 - mae: 0.3798 - mse: 0.2382 - val_loss: 0.5300 - val_mae: 0.5300 - val_mse: 0.5467\n",
      "Epoch 66/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4070 - mae: 0.4070 - mse: 0.2761\n",
      "Epoch 66: val_loss did not improve from 0.52998\n",
      "395/395 [==============================] - 186s 472ms/step - loss: 0.4070 - mae: 0.4070 - mse: 0.2761 - val_loss: 0.7046 - val_mae: 0.7046 - val_mse: 0.7813\n",
      "Epoch 67/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.4100 - mae: 0.4100 - mse: 0.2795\n",
      "Epoch 67: val_loss did not improve from 0.52998\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.4100 - mae: 0.4100 - mse: 0.2795 - val_loss: 1.0430 - val_mae: 1.0430 - val_mse: 1.5345\n",
      "Epoch 68/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3964 - mae: 0.3964 - mse: 0.3012\n",
      "Epoch 68: val_loss did not improve from 0.52998\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.3964 - mae: 0.3964 - mse: 0.3012 - val_loss: 0.6266 - val_mae: 0.6266 - val_mse: 0.6504\n",
      "Epoch 69/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3792 - mae: 0.3792 - mse: 0.2401\n",
      "Epoch 69: val_loss did not improve from 0.52998\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.3792 - mae: 0.3792 - mse: 0.2401 - val_loss: 0.5704 - val_mae: 0.5704 - val_mse: 0.5821\n",
      "Epoch 70/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3852 - mae: 0.3852 - mse: 0.2478\n",
      "Epoch 70: val_loss did not improve from 0.52998\n",
      "395/395 [==============================] - 188s 477ms/step - loss: 0.3852 - mae: 0.3852 - mse: 0.2478 - val_loss: 0.7425 - val_mae: 0.7425 - val_mse: 0.9134\n",
      "Epoch 71/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3921 - mae: 0.3921 - mse: 0.2522\n",
      "Epoch 71: val_loss did not improve from 0.52998\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3921 - mae: 0.3921 - mse: 0.2522 - val_loss: 0.9715 - val_mae: 0.9715 - val_mse: 1.3131\n",
      "Epoch 72/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3886 - mae: 0.3886 - mse: 0.2551\n",
      "Epoch 72: val_loss improved from 0.52998 to 0.51963, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 185s 468ms/step - loss: 0.3886 - mae: 0.3886 - mse: 0.2551 - val_loss: 0.5196 - val_mae: 0.5196 - val_mse: 0.5272\n",
      "Epoch 73/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3628 - mae: 0.3628 - mse: 0.2228\n",
      "Epoch 73: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 184s 466ms/step - loss: 0.3628 - mae: 0.3628 - mse: 0.2228 - val_loss: 0.7534 - val_mae: 0.7534 - val_mse: 0.9053\n",
      "Epoch 74/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3939 - mae: 0.3939 - mse: 0.2589\n",
      "Epoch 74: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 184s 466ms/step - loss: 0.3939 - mae: 0.3939 - mse: 0.2589 - val_loss: 0.8908 - val_mae: 0.8908 - val_mse: 1.2002\n",
      "Epoch 75/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3417 - mae: 0.3417 - mse: 0.1946\n",
      "Epoch 75: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 196s 496ms/step - loss: 0.3417 - mae: 0.3417 - mse: 0.1946 - val_loss: 1.0820 - val_mae: 1.0820 - val_mse: 1.5419\n",
      "Epoch 76/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3704 - mae: 0.3704 - mse: 0.2332\n",
      "Epoch 76: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 196s 495ms/step - loss: 0.3704 - mae: 0.3704 - mse: 0.2332 - val_loss: 0.8466 - val_mae: 0.8466 - val_mse: 1.1109\n",
      "Epoch 77/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3533 - mae: 0.3533 - mse: 0.2082\n",
      "Epoch 77: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 185s 467ms/step - loss: 0.3533 - mae: 0.3533 - mse: 0.2082 - val_loss: 0.5572 - val_mae: 0.5572 - val_mse: 0.6140\n",
      "Epoch 78/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3665 - mae: 0.3665 - mse: 0.2185\n",
      "Epoch 78: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 196s 496ms/step - loss: 0.3665 - mae: 0.3665 - mse: 0.2185 - val_loss: 0.6103 - val_mae: 0.6103 - val_mse: 0.6707\n",
      "Epoch 79/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3691 - mae: 0.3691 - mse: 0.2322\n",
      "Epoch 79: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 193s 488ms/step - loss: 0.3691 - mae: 0.3691 - mse: 0.2322 - val_loss: 0.7050 - val_mae: 0.7050 - val_mse: 0.8091\n",
      "Epoch 80/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3823 - mae: 0.3823 - mse: 0.2486\n",
      "Epoch 80: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.3823 - mae: 0.3823 - mse: 0.2486 - val_loss: 0.9767 - val_mae: 0.9767 - val_mse: 1.3031\n",
      "Epoch 81/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3513 - mae: 0.3513 - mse: 0.2080\n",
      "Epoch 81: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3513 - mae: 0.3513 - mse: 0.2080 - val_loss: 0.8886 - val_mae: 0.8886 - val_mse: 1.1164\n",
      "Epoch 82/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3619 - mae: 0.3619 - mse: 0.2303\n",
      "Epoch 82: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3619 - mae: 0.3619 - mse: 0.2303 - val_loss: 0.6002 - val_mae: 0.6002 - val_mse: 0.5971\n",
      "Epoch 83/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3558 - mae: 0.3558 - mse: 0.2110\n",
      "Epoch 83: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.3558 - mae: 0.3558 - mse: 0.2110 - val_loss: 0.5529 - val_mae: 0.5529 - val_mse: 0.5486\n",
      "Epoch 84/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3422 - mae: 0.3422 - mse: 0.1914\n",
      "Epoch 84: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3422 - mae: 0.3422 - mse: 0.1914 - val_loss: 1.0823 - val_mae: 1.0823 - val_mse: 1.5862\n",
      "Epoch 85/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3468 - mae: 0.3468 - mse: 0.1992\n",
      "Epoch 85: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 185s 470ms/step - loss: 0.3468 - mae: 0.3468 - mse: 0.1992 - val_loss: 1.0028 - val_mae: 1.0028 - val_mse: 1.5466\n",
      "Epoch 86/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3304 - mae: 0.3304 - mse: 0.1883\n",
      "Epoch 86: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.3304 - mae: 0.3304 - mse: 0.1883 - val_loss: 0.8285 - val_mae: 0.8285 - val_mse: 1.0967\n",
      "Epoch 87/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3573 - mae: 0.3573 - mse: 0.2217\n",
      "Epoch 87: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.3573 - mae: 0.3573 - mse: 0.2217 - val_loss: 1.1276 - val_mae: 1.1276 - val_mse: 1.7932\n",
      "Epoch 88/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3407 - mae: 0.3407 - mse: 0.1938\n",
      "Epoch 88: val_loss did not improve from 0.51963\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.3407 - mae: 0.3407 - mse: 0.1938 - val_loss: 1.2852 - val_mae: 1.2852 - val_mse: 2.2070\n",
      "Epoch 89/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3324 - mae: 0.3324 - mse: 0.1892\n",
      "Epoch 89: val_loss improved from 0.51963 to 0.47674, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 0.3324 - mae: 0.3324 - mse: 0.1892 - val_loss: 0.4767 - val_mae: 0.4767 - val_mse: 0.4616\n",
      "Epoch 90/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3278 - mae: 0.3278 - mse: 0.1840\n",
      "Epoch 90: val_loss did not improve from 0.47674\n",
      "395/395 [==============================] - 195s 495ms/step - loss: 0.3278 - mae: 0.3278 - mse: 0.1840 - val_loss: 0.7275 - val_mae: 0.7275 - val_mse: 0.8007\n",
      "Epoch 91/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3144 - mae: 0.3144 - mse: 0.1642\n",
      "Epoch 91: val_loss did not improve from 0.47674\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3144 - mae: 0.3144 - mse: 0.1642 - val_loss: 0.5157 - val_mae: 0.5157 - val_mse: 0.4999\n",
      "Epoch 92/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3468 - mae: 0.3468 - mse: 0.2021\n",
      "Epoch 92: val_loss improved from 0.47674 to 0.43224, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3468 - mae: 0.3468 - mse: 0.2021 - val_loss: 0.4322 - val_mae: 0.4322 - val_mse: 0.4015\n",
      "Epoch 93/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3234 - mae: 0.3234 - mse: 0.1745\n",
      "Epoch 93: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 184s 465ms/step - loss: 0.3234 - mae: 0.3234 - mse: 0.1745 - val_loss: 0.5004 - val_mae: 0.5004 - val_mse: 0.4893\n",
      "Epoch 94/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3163 - mae: 0.3163 - mse: 0.1700\n",
      "Epoch 94: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 189s 478ms/step - loss: 0.3163 - mae: 0.3163 - mse: 0.1700 - val_loss: 0.5534 - val_mae: 0.5534 - val_mse: 0.5191\n",
      "Epoch 95/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3053 - mae: 0.3053 - mse: 0.1529\n",
      "Epoch 95: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 188s 477ms/step - loss: 0.3053 - mae: 0.3053 - mse: 0.1529 - val_loss: 0.6012 - val_mae: 0.6012 - val_mse: 0.6308\n",
      "Epoch 96/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3105 - mae: 0.3105 - mse: 0.1609\n",
      "Epoch 96: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 188s 477ms/step - loss: 0.3105 - mae: 0.3105 - mse: 0.1609 - val_loss: 0.4889 - val_mae: 0.4889 - val_mse: 0.4450\n",
      "Epoch 97/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3170 - mae: 0.3170 - mse: 0.1670\n",
      "Epoch 97: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 187s 475ms/step - loss: 0.3170 - mae: 0.3170 - mse: 0.1670 - val_loss: 1.3007 - val_mae: 1.3007 - val_mse: 2.2277\n",
      "Epoch 98/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3265 - mae: 0.3265 - mse: 0.2055\n",
      "Epoch 98: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 189s 478ms/step - loss: 0.3265 - mae: 0.3265 - mse: 0.2055 - val_loss: 0.4932 - val_mae: 0.4932 - val_mse: 0.4657\n",
      "Epoch 99/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3278 - mae: 0.3278 - mse: 0.1744\n",
      "Epoch 99: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 189s 479ms/step - loss: 0.3278 - mae: 0.3278 - mse: 0.1744 - val_loss: 0.4959 - val_mae: 0.4959 - val_mse: 0.4722\n",
      "Epoch 100/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3021 - mae: 0.3021 - mse: 0.1532\n",
      "Epoch 100: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.3021 - mae: 0.3021 - mse: 0.1532 - val_loss: 0.4578 - val_mae: 0.4578 - val_mse: 0.4360\n",
      "Epoch 101/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3009 - mae: 0.3009 - mse: 0.1648\n",
      "Epoch 101: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.3009 - mae: 0.3009 - mse: 0.1648 - val_loss: 0.6341 - val_mae: 0.6341 - val_mse: 0.6637\n",
      "Epoch 102/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3045 - mae: 0.3045 - mse: 0.1579\n",
      "Epoch 102: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.3045 - mae: 0.3045 - mse: 0.1579 - val_loss: 0.5924 - val_mae: 0.5924 - val_mse: 0.5771\n",
      "Epoch 103/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2843 - mae: 0.2843 - mse: 0.1532\n",
      "Epoch 103: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.2843 - mae: 0.2843 - mse: 0.1532 - val_loss: 0.6114 - val_mae: 0.6114 - val_mse: 0.6197\n",
      "Epoch 104/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3006 - mae: 0.3006 - mse: 0.1479\n",
      "Epoch 104: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 187s 474ms/step - loss: 0.3006 - mae: 0.3006 - mse: 0.1479 - val_loss: 0.5903 - val_mae: 0.5903 - val_mse: 0.5906\n",
      "Epoch 105/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3056 - mae: 0.3056 - mse: 0.1640\n",
      "Epoch 105: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 190s 480ms/step - loss: 0.3056 - mae: 0.3056 - mse: 0.1640 - val_loss: 0.4363 - val_mae: 0.4363 - val_mse: 0.4012\n",
      "Epoch 106/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3057 - mae: 0.3057 - mse: 0.1590\n",
      "Epoch 106: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 189s 479ms/step - loss: 0.3057 - mae: 0.3057 - mse: 0.1590 - val_loss: 0.4679 - val_mae: 0.4679 - val_mse: 0.4517\n",
      "Epoch 107/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2919 - mae: 0.2919 - mse: 0.1451\n",
      "Epoch 107: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 188s 477ms/step - loss: 0.2919 - mae: 0.2919 - mse: 0.1451 - val_loss: 0.4864 - val_mae: 0.4864 - val_mse: 0.4502\n",
      "Epoch 108/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3016 - mae: 0.3016 - mse: 0.1626\n",
      "Epoch 108: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 189s 479ms/step - loss: 0.3016 - mae: 0.3016 - mse: 0.1626 - val_loss: 0.4675 - val_mae: 0.4675 - val_mse: 0.4338\n",
      "Epoch 109/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.3141 - mae: 0.3141 - mse: 0.1689\n",
      "Epoch 109: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 185s 468ms/step - loss: 0.3141 - mae: 0.3141 - mse: 0.1689 - val_loss: 0.6608 - val_mae: 0.6608 - val_mse: 0.6927\n",
      "Epoch 110/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2989 - mae: 0.2989 - mse: 0.1591\n",
      "Epoch 110: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 192s 485ms/step - loss: 0.2989 - mae: 0.2989 - mse: 0.1591 - val_loss: 0.6292 - val_mae: 0.6292 - val_mse: 0.6275\n",
      "Epoch 111/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2832 - mae: 0.2832 - mse: 0.1322\n",
      "Epoch 111: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 197s 497ms/step - loss: 0.2832 - mae: 0.2832 - mse: 0.1322 - val_loss: 0.9571 - val_mae: 0.9571 - val_mse: 1.2266\n",
      "Epoch 112/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2929 - mae: 0.2929 - mse: 0.1396\n",
      "Epoch 112: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 194s 491ms/step - loss: 0.2929 - mae: 0.2929 - mse: 0.1396 - val_loss: 0.4978 - val_mae: 0.4978 - val_mse: 0.4641\n",
      "Epoch 113/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2831 - mae: 0.2831 - mse: 0.1333\n",
      "Epoch 113: val_loss did not improve from 0.43224\n",
      "395/395 [==============================] - 199s 505ms/step - loss: 0.2831 - mae: 0.2831 - mse: 0.1333 - val_loss: 0.6871 - val_mae: 0.6871 - val_mse: 0.7417\n",
      "Epoch 114/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2876 - mae: 0.2876 - mse: 0.1444\n",
      "Epoch 114: val_loss improved from 0.43224 to 0.42698, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 196s 496ms/step - loss: 0.2876 - mae: 0.2876 - mse: 0.1444 - val_loss: 0.4270 - val_mae: 0.4270 - val_mse: 0.3876\n",
      "Epoch 115/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2756 - mae: 0.2756 - mse: 0.1248\n",
      "Epoch 115: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 194s 492ms/step - loss: 0.2756 - mae: 0.2756 - mse: 0.1248 - val_loss: 0.4718 - val_mae: 0.4718 - val_mse: 0.4362\n",
      "Epoch 116/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2722 - mae: 0.2722 - mse: 0.1267\n",
      "Epoch 116: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 191s 483ms/step - loss: 0.2722 - mae: 0.2722 - mse: 0.1267 - val_loss: 0.9267 - val_mae: 0.9267 - val_mse: 1.3032\n",
      "Epoch 117/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2880 - mae: 0.2880 - mse: 0.1464\n",
      "Epoch 117: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 201s 509ms/step - loss: 0.2880 - mae: 0.2880 - mse: 0.1464 - val_loss: 0.4731 - val_mae: 0.4731 - val_mse: 0.4516\n",
      "Epoch 118/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2890 - mae: 0.2890 - mse: 0.1376\n",
      "Epoch 118: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 195s 493ms/step - loss: 0.2890 - mae: 0.2890 - mse: 0.1376 - val_loss: 0.4787 - val_mae: 0.4787 - val_mse: 0.4931\n",
      "Epoch 119/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2863 - mae: 0.2863 - mse: 0.1374\n",
      "Epoch 119: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 194s 492ms/step - loss: 0.2863 - mae: 0.2863 - mse: 0.1374 - val_loss: 0.6658 - val_mae: 0.6658 - val_mse: 0.7043\n",
      "Epoch 120/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2816 - mae: 0.2816 - mse: 0.1317\n",
      "Epoch 120: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 188s 475ms/step - loss: 0.2816 - mae: 0.2816 - mse: 0.1317 - val_loss: 0.7208 - val_mae: 0.7208 - val_mse: 0.7900\n",
      "Epoch 121/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2719 - mae: 0.2719 - mse: 0.1255\n",
      "Epoch 121: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 191s 485ms/step - loss: 0.2719 - mae: 0.2719 - mse: 0.1255 - val_loss: 0.4722 - val_mae: 0.4722 - val_mse: 0.4489\n",
      "Epoch 122/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2701 - mae: 0.2701 - mse: 0.1172\n",
      "Epoch 122: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 187s 474ms/step - loss: 0.2701 - mae: 0.2701 - mse: 0.1172 - val_loss: 0.5236 - val_mae: 0.5236 - val_mse: 0.4648\n",
      "Epoch 123/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2670 - mae: 0.2670 - mse: 0.1195\n",
      "Epoch 123: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.2670 - mae: 0.2670 - mse: 0.1195 - val_loss: 0.4901 - val_mae: 0.4901 - val_mse: 0.4478\n",
      "Epoch 124/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2828 - mae: 0.2828 - mse: 0.1384\n",
      "Epoch 124: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.2828 - mae: 0.2828 - mse: 0.1384 - val_loss: 0.6750 - val_mae: 0.6750 - val_mse: 0.6898\n",
      "Epoch 125/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2683 - mae: 0.2683 - mse: 0.1198\n",
      "Epoch 125: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 186s 471ms/step - loss: 0.2683 - mae: 0.2683 - mse: 0.1198 - val_loss: 0.7512 - val_mae: 0.7512 - val_mse: 0.8678\n",
      "Epoch 126/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2742 - mae: 0.2742 - mse: 0.1269\n",
      "Epoch 126: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 191s 485ms/step - loss: 0.2742 - mae: 0.2742 - mse: 0.1269 - val_loss: 0.8031 - val_mae: 0.8031 - val_mse: 1.0194\n",
      "Epoch 127/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2567 - mae: 0.2567 - mse: 0.1064\n",
      "Epoch 127: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 190s 481ms/step - loss: 0.2567 - mae: 0.2567 - mse: 0.1064 - val_loss: 0.5795 - val_mae: 0.5795 - val_mse: 0.5751\n",
      "Epoch 128/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2585 - mae: 0.2585 - mse: 0.1118\n",
      "Epoch 128: val_loss did not improve from 0.42698\n",
      "395/395 [==============================] - 192s 487ms/step - loss: 0.2585 - mae: 0.2585 - mse: 0.1118 - val_loss: 0.5530 - val_mae: 0.5530 - val_mse: 0.5105\n",
      "Epoch 129/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2595 - mae: 0.2595 - mse: 0.1111\n",
      "Epoch 129: val_loss improved from 0.42698 to 0.41845, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 194s 490ms/step - loss: 0.2595 - mae: 0.2595 - mse: 0.1111 - val_loss: 0.4184 - val_mae: 0.4184 - val_mse: 0.3914\n",
      "Epoch 130/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2630 - mae: 0.2630 - mse: 0.1137\n",
      "Epoch 130: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 191s 484ms/step - loss: 0.2630 - mae: 0.2630 - mse: 0.1137 - val_loss: 0.4601 - val_mae: 0.4601 - val_mse: 0.4207\n",
      "Epoch 131/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2826 - mae: 0.2826 - mse: 0.1351\n",
      "Epoch 131: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 191s 483ms/step - loss: 0.2826 - mae: 0.2826 - mse: 0.1351 - val_loss: 0.5898 - val_mae: 0.5898 - val_mse: 0.5693\n",
      "Epoch 132/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2513 - mae: 0.2513 - mse: 0.1065\n",
      "Epoch 132: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 189s 477ms/step - loss: 0.2513 - mae: 0.2513 - mse: 0.1065 - val_loss: 0.4560 - val_mae: 0.4560 - val_mse: 0.4138\n",
      "Epoch 133/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2481 - mae: 0.2481 - mse: 0.1032\n",
      "Epoch 133: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 191s 484ms/step - loss: 0.2481 - mae: 0.2481 - mse: 0.1032 - val_loss: 0.5866 - val_mae: 0.5866 - val_mse: 0.5801\n",
      "Epoch 134/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2546 - mae: 0.2546 - mse: 0.1072\n",
      "Epoch 134: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 190s 482ms/step - loss: 0.2546 - mae: 0.2546 - mse: 0.1072 - val_loss: 0.4776 - val_mae: 0.4776 - val_mse: 0.4317\n",
      "Epoch 135/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2411 - mae: 0.2411 - mse: 0.0983\n",
      "Epoch 135: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 189s 479ms/step - loss: 0.2411 - mae: 0.2411 - mse: 0.0983 - val_loss: 0.4788 - val_mae: 0.4788 - val_mse: 0.4593\n",
      "Epoch 136/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2709 - mae: 0.2709 - mse: 0.1446\n",
      "Epoch 136: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 189s 478ms/step - loss: 0.2709 - mae: 0.2709 - mse: 0.1446 - val_loss: 0.5447 - val_mae: 0.5447 - val_mse: 0.5118\n",
      "Epoch 137/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2452 - mae: 0.2452 - mse: 0.1009\n",
      "Epoch 137: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 189s 477ms/step - loss: 0.2452 - mae: 0.2452 - mse: 0.1009 - val_loss: 0.6538 - val_mae: 0.6538 - val_mse: 0.6922\n",
      "Epoch 138/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2495 - mae: 0.2495 - mse: 0.1048\n",
      "Epoch 138: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 187s 475ms/step - loss: 0.2495 - mae: 0.2495 - mse: 0.1048 - val_loss: 0.4493 - val_mae: 0.4493 - val_mse: 0.4328\n",
      "Epoch 139/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2459 - mae: 0.2459 - mse: 0.1032\n",
      "Epoch 139: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 0.2459 - mae: 0.2459 - mse: 0.1032 - val_loss: 0.6106 - val_mae: 0.6106 - val_mse: 0.5910\n",
      "Epoch 140/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2369 - mae: 0.2369 - mse: 0.0930\n",
      "Epoch 140: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 187s 472ms/step - loss: 0.2369 - mae: 0.2369 - mse: 0.0930 - val_loss: 0.5689 - val_mae: 0.5689 - val_mse: 0.5924\n",
      "Epoch 141/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2481 - mae: 0.2481 - mse: 0.1106\n",
      "Epoch 141: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.2481 - mae: 0.2481 - mse: 0.1106 - val_loss: 0.7934 - val_mae: 0.7934 - val_mse: 0.8932\n",
      "Epoch 142/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2323 - mae: 0.2323 - mse: 0.0897\n",
      "Epoch 142: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 189s 479ms/step - loss: 0.2323 - mae: 0.2323 - mse: 0.0897 - val_loss: 0.4836 - val_mae: 0.4836 - val_mse: 0.4315\n",
      "Epoch 143/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2436 - mae: 0.2436 - mse: 0.0983\n",
      "Epoch 143: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 187s 474ms/step - loss: 0.2436 - mae: 0.2436 - mse: 0.0983 - val_loss: 0.5805 - val_mae: 0.5805 - val_mse: 0.5758\n",
      "Epoch 144/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2391 - mae: 0.2391 - mse: 0.0950\n",
      "Epoch 144: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 184s 467ms/step - loss: 0.2391 - mae: 0.2391 - mse: 0.0950 - val_loss: 0.6476 - val_mae: 0.6476 - val_mse: 0.6835\n",
      "Epoch 145/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2413 - mae: 0.2413 - mse: 0.0965\n",
      "Epoch 145: val_loss did not improve from 0.41845\n",
      "395/395 [==============================] - 185s 469ms/step - loss: 0.2413 - mae: 0.2413 - mse: 0.0965 - val_loss: 0.8949 - val_mae: 0.8949 - val_mse: 1.2066\n",
      "Epoch 146/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2456 - mae: 0.2456 - mse: 0.1050\n",
      "Epoch 146: val_loss improved from 0.41845 to 0.39736, saving model to checkpoint-150-epochs-8-batchs.h5\n",
      "395/395 [==============================] - 189s 478ms/step - loss: 0.2456 - mae: 0.2456 - mse: 0.1050 - val_loss: 0.3974 - val_mae: 0.3974 - val_mse: 0.3534\n",
      "Epoch 147/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2327 - mae: 0.2327 - mse: 0.0890\n",
      "Epoch 147: val_loss did not improve from 0.39736\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 0.2327 - mae: 0.2327 - mse: 0.0890 - val_loss: 0.4716 - val_mae: 0.4716 - val_mse: 0.4163\n",
      "Epoch 148/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2222 - mae: 0.2222 - mse: 0.0825\n",
      "Epoch 148: val_loss did not improve from 0.39736\n",
      "395/395 [==============================] - 186s 470ms/step - loss: 0.2222 - mae: 0.2222 - mse: 0.0825 - val_loss: 0.4731 - val_mae: 0.4731 - val_mse: 0.4708\n",
      "Epoch 149/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2451 - mae: 0.2451 - mse: 0.1016\n",
      "Epoch 149: val_loss did not improve from 0.39736\n",
      "395/395 [==============================] - 187s 473ms/step - loss: 0.2451 - mae: 0.2451 - mse: 0.1016 - val_loss: 0.4387 - val_mae: 0.4387 - val_mse: 0.4033\n",
      "Epoch 150/150\n",
      "395/395 [==============================] - ETA: 0s - loss: 0.2439 - mae: 0.2439 - mse: 0.0988\n",
      "Epoch 150: val_loss did not improve from 0.39736\n",
      "395/395 [==============================] - 187s 472ms/step - loss: 0.2439 - mae: 0.2439 - mse: 0.0988 - val_loss: 0.6547 - val_mae: 0.6547 - val_mse: 0.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd1183db190>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_aug_train, y_aug_train, batch_size=8, epochs=150, callbacks=checkpoint, validation_data=(X_aug_val,y_aug_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 148ms/step\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae : 0.947\n",
      "rmse : 1.179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "print('mae : {:.3f}'.format(mean_absolute_error(test_prediction, y_test)))\n",
    "print('rmse : {:.3f}'.format(np.sqrt(mean_squared_error(test_prediction, y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__원본 데이터__ <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batchsize : 16\n",
    "+ crop 이미지 전처리 안했을 때 mae : 1.139, rmse : 1.422\n",
    "+ crop 이미지 전처리 했을 때 mae : 1.880, rmse : 2.354\n",
    "+ 앞으로 전처리 안하고 진행\n",
    "\n",
    "batchsize : 8\n",
    "+ mae : 1.111, rmse : 1.400 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__data augmentation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본:회전:노이즈 = 1:1:1_\n",
    "+ mae : 0.836\n",
    "+ rmse : 1.068\n",
    "\n",
    "원본:회전:노이즈 = 2:1:1\n",
    "+ mae : 0.869\n",
    "+ rmse : 1.140"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "junoflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
